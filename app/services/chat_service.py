"""
ì±„íŒ… ì„œë¹„ìŠ¤ (LangGraph ì½”ì¹­ ì—ì´ì „íŠ¸ ì‹¤í–‰ - HITL ì§€ì›)
"""
from sqlalchemy.orm import Session
from fastapi import HTTPException
from app.models.chat import ChatMessage, MessageRole
from app.models.baby import BabyProfile
from app.agent.graph import get_agent_graph
from app.agent.state import AgentState
from app.dto.baby import AgeInfo, BabyAgentInfo
from app.services.chat_repository import get_or_create_session, get_conversation_history
from typing import Any, AsyncGenerator, Dict, List, Tuple
from langgraph.types import Command
from langchain_core.messages import HumanMessage, AIMessage
import uuid
import time
import asyncio
import logging
import json
from datetime import date, datetime, timezone

logger = logging.getLogger(__name__)


def _calculate_corrected_age(birth_date: date, due_date: date) -> AgeInfo:
    """
    êµì • ì—°ë ¹ ê³„ì‚°
    êµì • ì—°ë ¹ = í˜„ì¬ ë‚ ì§œ - ì¶œì‚° ì˜ˆì •ì¼
    """
    today = date.today()
    corrected_age_days = (today - due_date).days
    corrected_age_months = corrected_age_days / 30.44  # í‰ê·  ì›” ê¸¸ì´
    
    return AgeInfo(
        corrected_age_days=corrected_age_days,
        corrected_age_months=round(corrected_age_months, 1),
        chronological_age_days=(today - birth_date).days,
        chronological_age_months=round((today - birth_date).days / 30.44, 1)
    )


def _prepare_baby_info(baby: BabyProfile) -> BabyAgentInfo:
    """ì•„ê¸° ì •ë³´ë¥¼ AgentStateì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    age_info = _calculate_corrected_age(baby.birth_date, baby.due_date)
    
    return BabyAgentInfo(
        baby_id=str(baby.id),
        name=baby.name,
        birth_date=baby.birth_date.isoformat(),
        due_date=baby.due_date.isoformat(),
        gender=baby.gender,
        birth_weight=baby.birth_weight,
        medical_history=baby.medical_history or [],
        **age_info.model_dump()
    )


def _extract_doc_attr(doc: Any, attr: str, default: Any = "") -> Any:
    """ë¬¸ì„œ ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ì—ì„œ ì†ì„± ì¶”ì¶œ"""
    if isinstance(doc, dict):
        return doc.get(attr, default)
    return getattr(doc, attr, default)


def _load_session_data(db: Session, user_id: uuid.UUID, baby_id: uuid.UUID, session_id: uuid.UUID = None) -> Tuple:
    """ë™ê¸° DB ì‘ì—…: ì„¸ì…˜, ì•„ê¸° ì •ë³´, ëŒ€í™” ì´ë ¥ ë¡œë“œ (to_threadë¡œ í˜¸ì¶œ)"""
    session = get_or_create_session(db, user_id, baby_id, session_id)
    
    baby = db.query(BabyProfile).filter(
        BabyProfile.id == baby_id,
        BabyProfile.user_id == user_id
    ).first()
    
    return session, baby


def _load_conversation_history(db: Session, session_id: uuid.UUID) -> List:
    """ë™ê¸° DB ì‘ì—…: ëŒ€í™” ì´ë ¥ ë¡œë“œ (to_threadë¡œ í˜¸ì¶œ)"""
    return get_conversation_history(db, session_id)


def _save_results_to_db(
    db: Session,
    session,
    question: str,
    final_state: Dict,
) -> Tuple[str, List[Dict], List[Dict]]:
    """ë™ê¸° DB ì‘ì—…: ë©”ì‹œì§€ ì €ì¥ ë° ì»¤ë°‹ (to_threadë¡œ í˜¸ì¶œ)"""
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    user_message = ChatMessage(
        session_id=session.id,
        role=MessageRole.USER.value,
        content=question,
        is_emergency=False,
        created_at=datetime.now(timezone.utc)
    )
    db.add(user_message)
    
    # RAG ì†ŒìŠ¤ ì¶”ì¶œ
    extracted_rag_sources = []
    retrieved_docs = final_state.get("_retrieved_docs", [])
    if retrieved_docs:
        for doc in retrieved_docs:
            extracted_rag_sources.append({
                "doc_id": str(_extract_doc_attr(doc, "doc_id", "")),
                "chunk_index": _extract_doc_attr(doc, "chunk_index", ""),
                "score": _extract_doc_attr(doc, "score", 0.0),
                "filename": _extract_doc_attr(doc, "filename", ""),
                "category": _extract_doc_attr(doc, "category", "")
            })
    
    # QnA ì†ŒìŠ¤ ì¶”ì¶œ
    extracted_qna_sources = []
    qna_docs = final_state.get("_qna_docs", [])
    if qna_docs:
        for doc in qna_docs:
            extracted_qna_sources.append({
                "source_type": "qna",
                "qna_id": str(_extract_doc_attr(doc, "id", "") or ""),
                "filename": _extract_doc_attr(doc, "source", "") or "",
                "category": _extract_doc_attr(doc, "category", "") or "",
                "question": _extract_doc_attr(doc, "question", "") or "",
            })
    
    combined_sources = extracted_rag_sources + extracted_qna_sources
    final_response_text = final_state.get("response", "")
    
    # AI ì‘ë‹µ ì €ì¥
    assistant_message = ChatMessage(
        session_id=session.id,
        role=MessageRole.ASSISTANT.value,
        content=final_response_text,
        is_emergency=final_state.get("is_emergency", False),
        is_retry=final_state.get("is_retry", False),
        rag_sources=combined_sources if combined_sources else None,
        created_at=datetime.now(timezone.utc)
    )
    db.add(assistant_message)
    
    # ì„¸ì…˜ ì—…ë°ì´íŠ¸
    session.updated_at = datetime.now()
    db.add(session)
    if not session.title:
        session.title = question[:50]
    
    db.commit()
    
    return final_response_text, extracted_rag_sources, extracted_qna_sources


async def send_message(
    db: Session,
    user_id: uuid.UUID,
    baby_id: uuid.UUID,
    question: str,
    session_id: uuid.UUID = None
) -> AsyncGenerator[str, None]:
    """
    ë©”ì‹œì§€ ì „ì†¡ ë° ì½”ì¹­ ì—ì´ì „íŠ¸ ì‹¤í–‰ (í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° + HITL)
    
    ìŠ¤íŠ¸ë¦¬ë° ëŒ€ìƒ: coach_agent, closing ë…¸ë“œì˜ LLM ì‘ë‹µë§Œ (stream_response íƒœê·¸)
    
    HITL íë¦„:
    1. ì²« ë©”ì‹œì§€: intent â†’ ask_situation â†’ [INTERRUPT 1: ìƒí™© ë‹µë³€ ëŒ€ê¸°]
    2. ìƒí™© ë‹µë³€: Command(resume) â†’ goal_options â†’ [INTERRUPT 2: ëª©í‘œ ì„ íƒ ëŒ€ê¸°]
    3. ëª©í‘œ ì„ íƒ: Command(resume) â†’ research_agent â†’ evaluate_docs â†’ response_node
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        user_id: ì‚¬ìš©ì ID
        baby_id: ì•„ê¸° ID
        question: ì‚¬ìš©ì ì§ˆë¬¸
        session_id: ì„¸ì…˜ ID (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    
    Yields:
        SSE ì´ë²¤íŠ¸ ë°ì´í„° (JSON ë¬¸ìì—´)
    """
    start_time = time.time()
    
    try:
        # 1. ì„¸ì…˜ ë° ì•„ê¸° ì •ë³´ ë¡œë“œ (ë™ê¸° DB â†’ to_thread)
        session, baby = await asyncio.to_thread(
            _load_session_data, db, user_id, baby_id, session_id
        )
        
        if not baby:
            yield json.dumps({
                "type": "error",
                "detail": "ì•„ê¸° í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }, ensure_ascii=False)
            return
        
        # 3. ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ê°€ì ¸ì˜¤ê¸° (async)
        agent_graph = await get_agent_graph()
        
        # 4. thread_id ê¸°ë°˜ config (ì²´í¬í¬ì¸í„° ìƒíƒœ ê´€ë¦¬)
        thread_id = str(session.id)
        config = {"configurable": {"thread_id": thread_id}}
        
        # 5. ì²´í¬í¬ì¸í„°ì—ì„œ ê¸°ì¡´ ìƒíƒœ í™•ì¸ 
        existing_state = await agent_graph.aget_state(config)
        
        # interrupt ìƒíƒœ(nextê°€ ì¡´ì¬)ë¼ë©´ ë¬´ì¡°ê±´ ì¬ê°œ
        is_resuming = (
            existing_state 
            and existing_state.next 
            and len(existing_state.next) > 0
        )
        
        logger.info(f"========== ğŸ˜Š ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘: session_id={session.id}, is_resuming={is_resuming}, question={question[:50]}... ==========")
        
        final_state = {}
        
        if is_resuming:
            # ===== HITL ì¬ê°œ ëª¨ë“œ =====
            # ì‚¬ìš©ì ì‘ë‹µì„ resume ê°’ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ interrupted ê·¸ë˜í”„ë¥¼ ì¬ê°œ
            logger.info(f"ğŸ”„ ì½”ì¹­ ë£¨í”„ ì¬ê°œ (thread_id={thread_id})")
            
            graph_input = Command(
                resume=question,
                update={
                    "messages": [HumanMessage(content=question)]
                }
            )
        else:
            # ===== ì‹ ê·œ ì‹¤í–‰ ëª¨ë“œ =====
            # ëŒ€í™” ì´ë ¥ ë¡œë“œ ë° ì´ˆê¸° ìƒíƒœ êµ¬ì„±
            # ëŒ€í™” ì´ë ¥ ë¡œë“œ (ë™ê¸° DB â†’ to_thread)
            conversation_history = await asyncio.to_thread(
                _load_conversation_history, db, session.id
            )
            
            history_messages = []
            if conversation_history:
                for msg in conversation_history:
                    content = msg.content
                    if msg.role == "user":
                        history_messages.append(HumanMessage(content=content))
                    elif msg.role == "assistant":
                        is_retry = getattr(msg, "is_retry", False)
                        history_messages.append(AIMessage(content=content, additional_kwargs={"is_retry": is_retry}))
            
            history_messages.append(HumanMessage(content=question))
            
            graph_input: AgentState = {
                "question": question,
                "previous_question": question,
                "session_id": session.id,
                "user_id": user_id,
                "messages": history_messages,
                "baby_info": _prepare_baby_info(baby).model_dump(),
                "_retrieved_docs": [],
                "_qna_docs": [],
                "_doc_relevance_score": None,
                "_doc_relevance_passed": False,
                "response": "",
                "is_emergency": False,
                "response_time": None,
                "_intent": None,
                "goal": None,
                "goal_options": None
            }
        
        # 6. astream_eventsë¡œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°
        # coach_agent, closing ë…¸ë“œì—ì„œ "stream_response" íƒœê·¸ê°€ ë¶™ì€ LLM í˜¸ì¶œë§Œ ìŠ¤íŠ¸ë¦¬ë°
        async for event in agent_graph.astream_events(graph_input, config=config, version="v2"):
            event_type = event.get("event")
            data = event.get("data", {})
            tags = event.get("tags", [])
            
            # LLM í† í° ìŠ¤íŠ¸ë¦¬ë° (stream_response íƒœê·¸ ê¸°ë°˜ í•„í„°ë§)
            # coach_agent_node, closing_nodeì—ì„œ config={"tags": ["stream_response"]}ë¡œ í˜¸ì¶œí•œ ê²ƒë§Œ ëŒ€ìƒ
            if event_type == "on_chat_model_stream" and "stream_response" in tags:
                chunk = data.get("chunk")
                if chunk and hasattr(chunk, "content") and chunk.content:
                    yield json.dumps({
                        "type": "chunk",
                        "content": chunk.content
                    }, ensure_ascii=False)

        # 7. ì²´í¬í¬ì¸í„°ì—ì„œ í™•ì •ëœ ìµœì¢… ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        saved_state = await agent_graph.aget_state(config)
        if saved_state and saved_state.values:
            final_state = saved_state.values
        
        # 8. ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = time.time() - start_time
        
        # 9. DB ì €ì¥ (ë™ê¸° DB â†’ to_thread)
        final_response_text, extracted_rag_sources, extracted_qna_sources = await asyncio.to_thread(
            _save_results_to_db, db, session, question, final_state
        )
        
        logger.info(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ: response_time={response_time:.2f}s")
        
        # 11. ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡ (ì½”ì¹­ ë©”íƒ€ë°ì´í„° í¬í•¨)
        done_event = {
            "type": "done",
            "response": final_response_text,
            "session_id": str(session.id),
            "is_emergency": final_state.get("is_emergency", False),
            "rag_sources": extracted_rag_sources,
            "qna_sources": extracted_qna_sources,
            "response_time": response_time,
            "coaching": {
                "goal": final_state.get("goal"),
                "goal_options": final_state.get("goal_options")
            }
        }
        
        yield json.dumps(done_event, ensure_ascii=False)
        
    except HTTPException as he:
        yield json.dumps({
            "type": "error",
            "detail": he.detail
        }, ensure_ascii=False)
    except Exception as e:
        logger.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        db.rollback()
        yield json.dumps({
            "type": "error",
            "detail": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }, ensure_ascii=False)
