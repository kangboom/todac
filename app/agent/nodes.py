"""
ë…¸ë“œ í•¨ìˆ˜ (Self-RAG êµ¬ì¡°)
"""
from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AIMessage
from app.agent.state import AgentState
from app.agent.prompts import (
    DOC_RELEVANCE_PROMPT_TEMPLATE, 
    RESPONSE_GENERATION_PROMPT_TEMPLATE,
    AGENT_NODE_PROMPT_TEMPLATE,
    get_baby_context_string,
    get_docs_context_string,
    SIMPLE_RESPONSE_PROMPT_TEMPLATE,
    INTENT_CLASSIFICATION_PROMPT_TEMPLATE,
    ASK_FOR_INFO_PROMPT_TEMPLATE,
    EMERGENCY_RESPONSE_PROMPT_TEMPLATE,
    # ì½”ì¹­ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
    GOAL_SETTER_PROMPT_TEMPLATE,
    GOAL_SETTER_RESET_PROMPT_TEMPLATE,
    GOAL_SETTER_MESSAGE_PROMPT_TEMPLATE,
    GOAL_EVALUATOR_SYSTEM_PROMPT,
    GOAL_EVALUATOR_PROMPT_TEMPLATE,
    COACH_AGENT_PROMPT_TEMPLATE,
    COACH_TOOL_CALL_PROMPT_TEMPLATE,
    EVALUATOR_PROMPT_TEMPLATE,
    COACHING_EVALUATOR_SYSTEM_PROMPT,
    CLOSING_PROMPT_TEMPLATE,
)
from app.agent.tools import milvus_knowledge_search, retrieve_qna
from app.services.qna_service import format_qna_docs
from app.dto.qna import QnADoc
from app.dto.rag import RagDoc
from app.core.llm_factory import get_generator_llm, get_evaluator_llm
from app.agent.utils import parse_json_from_response, track_node_execution_time
import logging

logger = logging.getLogger(__name__)

@track_node_execution_time("intent_classifier")
async def intent_classifier_node(state: AgentState) -> AgentState:
    """
    ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ
    ì§ˆë¬¸ì´ 'ë¯¸ìˆ™ì•„ ëŒë´„' ë²”ìœ„ì¸ì§€ íŒë‹¨ + 'ë¶€ì¡±í•œ ì •ë³´ ì œê³µ' ì—¬ë¶€ íŒë‹¨
    """
    logger.info("===== ğŸ¤– ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ ì‹¤í–‰ =====")
    
    question = state.get("question", "")
    
    llm = get_evaluator_llm()
    if not llm:
        logger.warning("í‰ê°€ ëª¨ë¸ ì—†ìŒ, ê¸°ë³¸ê°’(relevant) ì„¤ì •")
        state["_intent"] = "irrelevant"
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return state
        
    try:

        messages = state.get("messages", [])
        recent_history = messages[-5:] if len(messages) > 5 else messages
        input_messages = [SystemMessage(content=INTENT_CLASSIFICATION_PROMPT_TEMPLATE)] + recent_history
        
        response = await llm.ainvoke(input_messages)
        response_text = response.content.strip()
        
        result = parse_json_from_response(response_text)
        
        intent = result.get("intent", "relevant")
        reason = result.get("reason", "")
        
        logger.info(f"âœ… ì˜ë„ ë¶„ë¥˜ ê²°ê³¼: {intent} (ì´ìœ : {reason}) âœ…")
        state["_intent"] = intent
        
        # irrelevantì¸ ê²½ìš° ì¦‰ì‹œ ë‹µë³€ ìƒì„±
        if intent == "irrelevant":
            logger.info("ğŸš« ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ -> ì¦‰ì‹œ ê±°ì ˆ ì‘ë‹µ ìƒì„± ğŸš«")
            try:
                simple_prompt = SIMPLE_RESPONSE_PROMPT_TEMPLATE.format(question=question)
                gen_llm = get_generator_llm()
                if gen_llm:

                    # ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ íƒœê·¸ ì¶”ê°€
                    resp = await gen_llm.ainvoke(
                        [HumanMessage(content=simple_prompt)],
                        config={"tags": ["stream_response"]}
                    )
                    state["response"] = resp.content.strip()
                    state["messages"] = [resp]
                else:
                    state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ë¯¸ìˆ™ì•„ ë° ì‹ ìƒì•„ ëŒë´„ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            except Exception as ex:
                logger.error(f"ê±°ì ˆ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(ex)}")
                state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        logger.error(f"ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
        state["_intent"] = "relevant"
        
    return state

@track_node_execution_time("emergency_response")
async def emergency_response_node(state: AgentState) -> AgentState:
    """
    [í†µí•©] ì‘ê¸‰ ìƒí™© ì „ìš© ë…¸ë“œ (ê²€ìƒ‰ + ë‹µë³€ ìƒì„±)
    - ë³„ë„ì˜ í‰ê°€ ë…¸ë“œ ì—†ì´ ì¦‰ì‹œ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ê²€ìƒ‰ëœ ëª¨ë“  ë¬¸ì„œë¥¼ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë§Œ ì„ ë³„í•´ ë‹µë³€í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    logger.info("===== ğŸš¨ Emergency Response ë…¸ë“œ ì‹¤í–‰ (Fast-Track) =====")
    
    question = state.get("question", "")
    baby_info = state.get("baby_info", {})
    state["is_emergency"] = True
    qna_docs = []
    rag_docs = []
    
    try:
        # 1. QnA ê²€ìƒ‰ (invoke ëŒ€ì‹  .func ì‚¬ìš©)
        # .funcë¥¼ í˜¸ì¶œí•˜ë©´ ë°ì½”ë ˆì´í„° í¬ì¥ì„ ë²—ê¸°ê³  (content, artifact) íŠœí”Œì„ ì§ì ‘ ë°›ìŠµë‹ˆë‹¤.
        qna_content, qna_artifacts = retrieve_qna.func(query=question)
        
        if qna_artifacts:
            for d in qna_artifacts:
                qna_docs.append(QnADoc(**d))
        
        # 2. Milvus ê²€ìƒ‰ (.func ì‚¬ìš©)
        # ì¸ìë¥¼ í‚¤ì›Œë“œ ì•„ê·œë¨¼íŠ¸(kwargs) í˜•íƒœë¡œ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        milvus_content, milvus_artifacts = milvus_knowledge_search.func(query=question)
        
        if milvus_artifacts:
            for d in milvus_artifacts:
                rag_docs.append(RagDoc(**d))

        # ê²°ê³¼ ì €ì¥
        state["_qna_docs"] = qna_docs
        state["_retrieved_docs"] = rag_docs
        logger.info(f"ğŸš¨ ì‘ê¸‰ ê²€ìƒ‰ ì™„ë£Œ: {qna_content} {milvus_content}")
        
    except Exception as e:
        logger.error(f"ì‘ê¸‰ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜(ë¬´ì‹œí•˜ê³  ì§„í–‰): {str(e)}")

    # 3. [ìƒì„±] ì‘ê¸‰ ë‹µë³€ ìƒì„±
    llm = get_generator_llm()
    if not llm:
        state["response"] = "ì‹œìŠ¤í…œ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì¦‰ì‹œ 119ì— ì—°ë½í•˜ê±°ë‚˜ ë³‘ì›ì„ ë°©ë¬¸í•˜ì„¸ìš”."
        return state
        
    try:
        baby_context = get_baby_context_string(baby_info)
        
        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        formatted_qna = format_qna_docs(qna_docs) if qna_docs else ""
        rag_context = get_docs_context_string(rag_docs)
        
        docs_context = ""
        if formatted_qna:
            docs_context += f"[QnA ì •ë³´]\n{formatted_qna}\n\n"
        if rag_context:
            docs_context += f"[ê²€ìƒ‰ëœ ë¬¸ì„œ]\n{rag_context}\n\n"
        if not docs_context:
            docs_context = "ê´€ë ¨ëœ ì°¸ì¡° ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì˜í•™ì  ìƒì‹ì— ê¸°ë°˜í•´ ë‹µë³€í•˜ì„¸ìš”."

        prompt = EMERGENCY_RESPONSE_PROMPT_TEMPLATE.format(
            baby_context=baby_context,
            docs_context=docs_context,
            question=question
        )
        
        # ìµœê·¼ ëŒ€í™” 5ê°œë§Œ ì°¸ì¡°
        messages = state.get("messages", [])
        clean_messages = get_clean_messages_for_generation(messages)
        recent_history = clean_messages[-5:] if len(clean_messages) > 5 else clean_messages
        
        response = await llm.ainvoke(
            [SystemMessage(content=prompt)] + recent_history,
            config={"tags": ["stream_response"]}
        )
        
        state["response"] = response.content.strip()
        state["messages"] = [response]
        
    except Exception as e:
        logger.error(f"ì‘ê¸‰ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ê°€ê¹Œìš´ ë³‘ì› ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”."
        
    return state


@track_node_execution_time("goal_setter")
async def goal_setter_node(state: AgentState) -> AgentState:
    """
    Goal Setter ë…¸ë“œ (ì½”ì¹­ ì—ì´ì „íŠ¸)
    ì‚¬ìš©ì ë°œí™”ì—ì„œ 'í•´ê²°í•˜ê³  ì‹¶ì€ ë¬¸ì œ'ë¥¼ ì¶”ì¶œí•˜ì—¬ êµ¬ì²´ì ì¸ ëª©í‘œì™€ ë‹¨ê³„ë¥¼ ìˆ˜ë¦½.
    
    [ì‹¤í–‰ ë‹¨ê³„ 2-Step]
    1. JSON ì¶”ì¶œ: LLMì—ê²Œ Goal, Stepsë¥¼ JSONìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ìš”ì²­
    2. ë©”ì‹œì§€ ìƒì„±(ìŠ¤íŠ¸ë¦¬ë°): ì¶”ì¶œëœ Goal, Stepsë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
    
    ì¬ì„¤ì • ëª¨ë“œ: _goal_feedbackê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ëª©í‘œë¥¼ ì¬ìˆ˜ë¦½.
    """
    logger.info("===== ğŸ¯ Goal Setter ë…¸ë“œ ì‹¤í–‰ =====")
    
    question = state.get("question", "")
    baby_info = state.get("baby_info", {})
    messages = state.get("messages", [])
    goal_feedback = state.get("_goal_feedback", "")
    prev_goal = state.get("goal", "")
    prev_steps = state.get("coaching_steps", [])
    
    llm = get_generator_llm()
    if not llm:
        logger.error("LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ëª©í‘œ ì„¤ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì½”ì¹­ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        state["goal_status"] = "ready"
        return state
    
    try:
        baby_context = get_baby_context_string(baby_info)
        
        # [Step 1] JSON ì¶”ì¶œ (Goal + Steps)
        system_prompt = GOAL_SETTER_PROMPT_TEMPLATE.format(
            baby_context=baby_context
        )
        
        # ì¬ì„¤ì • ëª¨ë“œ: ì´ì „ ê³„íšê³¼ ì‚¬ìš©ì í”¼ë“œë°±ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        if goal_feedback and prev_goal:
            prev_steps_str = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(prev_steps)]) if prev_steps else "ì—†ìŒ"
            system_prompt += GOAL_SETTER_RESET_PROMPT_TEMPLATE.format(
                prev_goal=prev_goal,
                prev_steps_str=prev_steps_str,
                goal_feedback=goal_feedback
            )
            logger.info(f"ğŸ”„ ëª©í‘œ ì¬ì„¤ì • ëª¨ë“œ (í”¼ë“œë°±: {goal_feedback[:50]}...)")
        
        clean_messages = get_clean_messages_for_generation(messages)
        recent_history = clean_messages[-5:] if len(clean_messages) > 5 else clean_messages
        recent_history = sanitize_messages_for_llm(recent_history)
        
        # JSON ì¶”ì¶œìš© í˜¸ì¶œ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
        input_messages = [SystemMessage(content=system_prompt)] + recent_history
        response = await llm.ainvoke(input_messages)
        response_text = response.content.strip()
        
        result = parse_json_from_response(response_text)
        
        goal = result.get("goal", "")
        steps = result.get("steps", [])
        
        if not goal or not steps:
            logger.warning("âš ï¸ ëª©í‘œ/ë‹¨ê³„ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜")
            state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì½”ì¹­ ëª©í‘œë¥¼ ì„¤ì •í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì´ ê±±ì •ë˜ì‹œëŠ”ì§€ ì¢€ ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            state["goal_status"] = "ready"
            state["messages"] = [AIMessage(content=state["response"])]
            return state

        # [Step 2] ë©”ì‹œì§€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
        steps_str = "\n".join([f"{i+1}. {s}" for i, s in enumerate(steps)])
        
        message_prompt = GOAL_SETTER_MESSAGE_PROMPT_TEMPLATE.format(
            baby_context=baby_context,
            goal=goal,
            steps_str=steps_str
        )
        
        # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        msg_response = await llm.ainvoke(
            [SystemMessage(content=message_prompt)], # System promptë§Œìœ¼ë¡œ ìƒì„± (íˆìŠ¤í† ë¦¬ëŠ” ì´ë¯¸ ë°˜ì˜ë¨)
            config={"tags": ["stream_response"]}
        )
        
        message = msg_response.content.strip()
        
        state["goal"] = goal
        state["coaching_steps"] = steps
        state["current_step_idx"] = 0
        state["goal_status"] = "in_progress"
        state["_goal_feedback"] = None  # í”¼ë“œë°± ì´ˆê¸°í™”
        state["_goal_approved"] = None  # ìŠ¹ì¸ ìƒíƒœ ì´ˆê¸°í™”
        state["response"] = message
        state["messages"] = [msg_response]
        
        logger.info(f"âœ… ëª©í‘œ ì„¤ì • ì™„ë£Œ: {goal}")
        logger.info(f"âœ… ë‹¨ê³„ ìˆ˜ë¦½: {len(steps)}ê°œ ë‹¨ê³„")
        logger.info("âœ… ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ (ìŠ¤íŠ¸ë¦¬ë°)")

    except Exception as e:
        logger.error(f"ëª©í‘œ ì„¤ì • ì‹¤íŒ¨: {str(e)}", exc_info=True)
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì½”ì¹­ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        state["goal_status"] = "ready"
        state["messages"] = [AIMessage(content=state["response"])]
    
    return state


@track_node_execution_time("goal_evaluator")
async def goal_evaluator_node(state: AgentState) -> AgentState:
    """
    Goal Evaluator ë…¸ë“œ (ì½”ì¹­ ì—ì´ì „íŠ¸)
    Goal Setterê°€ ìˆ˜ë¦½í•œ ëª©í‘œ/ê³„íšì— ëŒ€í•œ ì‚¬ìš©ìì˜ ìŠ¹ì¸ ì—¬ë¶€ë¥¼ íŒë‹¨.
    
    - approved: coach_agentë¡œ ì§„í–‰ (ì½”ì¹­ ì‹œì‘)
    - modify: goal_setterë¡œ ë³µê·€ (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ì¬ì„¤ì •)
    """
    logger.info("===== âœ… Goal Evaluator ë…¸ë“œ ì‹¤í–‰ =====")
    
    messages = state.get("messages", [])
    goal = state.get("goal", "")
    coaching_steps = state.get("coaching_steps", [])
    
    # ì‚¬ìš©ìì˜ ìµœì‹  ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_message = msg.content
            break
    
    if not user_message:
        logger.warning("âš ï¸ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(approved) ì²˜ë¦¬")
        state["_goal_approved"] = True
        return state
    
    llm = get_evaluator_llm()
    if not llm:
        logger.warning("âš ï¸ í‰ê°€ ëª¨ë¸ì´ ì—†ì–´ ê¸°ë³¸ê°’(approved)ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        state["_goal_approved"] = True
        return state
    
    try:
        all_steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(coaching_steps)])
        
        eval_prompt = GOAL_EVALUATOR_PROMPT_TEMPLATE.format(
            goal=goal,
            all_steps=all_steps,
            user_message=user_message
        )
        
        eval_messages = [
            SystemMessage(content=GOAL_EVALUATOR_SYSTEM_PROMPT),
            HumanMessage(content=eval_prompt)
        ]
        
        response = await llm.ainvoke(eval_messages)
        response_text = response.content.strip()
        
        result = parse_json_from_response(response_text)
        
        decision = result.get("decision", "approved")
        reason = result.get("reason", "")
        feedback = result.get("feedback", "")
        
        logger.info(f"âœ… Goal Evaluator íŒë‹¨: {decision} (ì´ìœ : {reason})")
        
        if decision == "approved":
            state["_goal_approved"] = True
            logger.info("ğŸ‘ ëª©í‘œ ìŠ¹ì¸ â†’ Coach Agentë¡œ ì§„í–‰")
        else:
            state["_goal_approved"] = False
            state["_goal_feedback"] = feedback or user_message
            logger.info(f"âœï¸ ëª©í‘œ ìˆ˜ì • ìš”ì²­ â†’ Goal Setterë¡œ ë³µê·€ (í”¼ë“œë°±: {feedback[:50]}...)")
        
    except Exception as e:
        logger.error(f"Goal Evaluator ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ approved
        state["_goal_approved"] = True
        logger.info("âš ï¸ í‰ê°€ ì‹¤íŒ¨, ê¸°ë³¸ê°’(approved)ìœ¼ë¡œ Coach Agent ì§„í–‰")
    
    return state



@track_node_execution_time("coach_agent")
async def coach_agent_node(state: AgentState) -> AgentState:
    """
    Coach Agent ë…¸ë“œ (ì½”ì¹­ ì—ì´ì „íŠ¸)
    
    2ê°€ì§€ ëª¨ë“œ:
    1) Tool í˜¸ì¶œ ëª¨ë“œ: LLMì´ tool_callsë¥¼ ë°˜í™˜ â†’ ToolNodeë¡œ ë¼ìš°íŒ…
    2) ì‘ë‹µ ìƒì„± ëª¨ë“œ: ToolMessage(ê²€ìƒ‰ ê²°ê³¼)ë¥¼ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¡°í•© â†’ ìµœì¢… ê°€ì´ë“œ ìŠ¤íŠ¸ë¦¬ë°
    
    ì´ ë…¸ë“œ ì‹¤í–‰ í›„ (ì‘ë‹µ ìƒì„± ì™„ë£Œ ì‹œ) interruptë˜ì–´ ì‚¬ìš©ì ì…ë ¥ì„ ëŒ€ê¸°í•©ë‹ˆë‹¤.
    """
    logger.info("===== ğŸ‹ï¸ Coach Agent ë…¸ë“œ ì‹¤í–‰ =====")
    
    goal = state.get("goal", "")
    coaching_steps = state.get("coaching_steps", [])
    current_step_idx = state.get("current_step_idx", 0)
    baby_info = state.get("baby_info", {})
    messages = state.get("messages", [])
    
    if not coaching_steps or current_step_idx >= len(coaching_steps):
        logger.warning("âš ï¸ ìœ íš¨í•œ ì½”ì¹­ ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        state["response"] = "ì½”ì¹­ ì„¸ì…˜ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        state["goal_status"] = "completed"
        return state
    
    current_step = coaching_steps[current_step_idx]
    
    llm = get_generator_llm()
    if not llm:
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê°€ì´ë“œë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state
    
    # ===== ToolMessage ì²˜ë¦¬: ì´ì „ Tool ì‹¤í–‰ ê²°ê³¼ì—ì„œ ë¬¸ì„œ ì¶”ì¶œ =====
    has_tool_results = False
    new_retrieved_docs = []
    new_qna_docs = []
    
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            break  # í˜„ì¬ í„´ì˜ ì‚¬ìš©ì ë©”ì‹œì§€ ì´ì „ê¹Œì§€ë§Œ í™•ì¸
        if isinstance(msg, AIMessage):
            continue
        if isinstance(msg, ToolMessage):
            has_tool_results = True
            tool_name = getattr(msg, "name", "")
            raw_data = getattr(msg, "artifact", None)
            if not raw_data:
                continue
            
            logger.info(f"ğŸ” ToolMessage Artifact ì¶”ì¶œ: {tool_name}")
            if tool_name == "milvus_knowledge_search":
                for d in raw_data:
                    try:
                        new_retrieved_docs.append(RagDoc(**d))
                    except Exception as e:
                        logger.error(f"RagDoc ë³€í™˜ ì‹¤íŒ¨: {e}")
            elif tool_name == "retrieve_qna":
                for d in raw_data:
                    try:
                        new_qna_docs.append(QnADoc(**d))
                    except Exception as e:
                        logger.error(f"QnADoc ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    if new_retrieved_docs:
        state["_retrieved_docs"] = new_retrieved_docs
        logger.info(f"âœ… RAG ë¬¸ì„œ State ì—…ë°ì´íŠ¸: {len(new_retrieved_docs)}ê°œ")
    if new_qna_docs:
        state["_qna_docs"] = new_qna_docs
        logger.info(f"âœ… QnA ë¬¸ì„œ State ì—…ë°ì´íŠ¸: {len(new_qna_docs)}ê°œ")
    
    # ===== ëª¨ë“œ ê²°ì • =====
    if not has_tool_results:
        # ---- ëª¨ë“œ 1: Tool í˜¸ì¶œ ëª¨ë“œ (LLMì—ê²Œ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì œê³µ) ----
        logger.info("ğŸ“¡ Tool í˜¸ì¶œ ëª¨ë“œ: LLMì´ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.")
        
        tools = [milvus_knowledge_search, retrieve_qna]
        model_with_tools = llm.bind_tools(tools)
        
        baby_context = get_baby_context_string(baby_info)
        all_steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(coaching_steps)])
        
        tool_prompt = COACH_TOOL_CALL_PROMPT_TEMPLATE.format(
            baby_context=baby_context,
            goal=goal,
            all_steps=all_steps,
            current_step=current_step,
            step_number=current_step_idx + 1,
            total_steps=len(coaching_steps)
        )

        clean_messages = get_clean_messages_for_generation(messages)
        recent_history = clean_messages[-5:] if len(clean_messages) > 5 else clean_messages
        recent_history = sanitize_messages_for_llm(recent_history)
        tool_messages = [SystemMessage(content=tool_prompt)] + recent_history
        
        response = await model_with_tools.ainvoke(tool_messages)
        state["messages"] = [response]
        
        # tool_callsê°€ ìˆìœ¼ë©´ ToolNodeê°€ ì²˜ë¦¬, ì—†ìœ¼ë©´ ë°”ë¡œ ì‘ë‹µ ìƒì„± ëª¨ë“œë¡œ ì „í™˜
        if response.tool_calls:
            logger.info(f"ğŸ”§ Tool í˜¸ì¶œ ìš”ì²­: {[tc['name'] for tc in response.tool_calls]}")
        else:
            logger.info("â„¹ï¸ LLMì´ Tool í˜¸ì¶œ ì—†ì´ ì‘ë‹µ â†’ ë°”ë¡œ ì‘ë‹µ ìƒì„± ëª¨ë“œë¡œ ì „í™˜")
        
        return state
    
    # ---- ëª¨ë“œ 2: ì‘ë‹µ ìƒì„± ëª¨ë“œ (Tool ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ê°€ì´ë“œ ìƒì„±) ----
    logger.info("ğŸ“ ì‘ë‹µ ìƒì„± ëª¨ë“œ: Tool ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì½”ì¹­ ê°€ì´ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.")
    
    # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    rag_docs = state.get("_retrieved_docs", [])
    qna_docs = state.get("_qna_docs", [])
    
    formatted_qna = format_qna_docs(qna_docs) if qna_docs else ""
    rag_context = get_docs_context_string(rag_docs)
    
    docs_context = ""
    if formatted_qna:
        docs_context += f"[QnA ì •ë³´]\n{formatted_qna}\n\n"
    if rag_context:
        docs_context += f"[ê²€ìƒ‰ëœ ë¬¸ì„œ]\n{rag_context}\n\n"
    if not docs_context:
        docs_context = "ê´€ë ¨ëœ ì°¸ì¡° ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì´ë“œí•´ì£¼ì„¸ìš”."
    
    # ì´ì „ í‰ê°€ ê²°ê³¼ (ì¬ì‹œë„ ì‹œ ë‹¤ë¥¸ ë°©ë²• ì œì•ˆìš©)
    eval_context = "ì—†ìŒ (ì²« ì‹œë„)"
    for msg in reversed(messages):
        if isinstance(msg, AIMessage) and hasattr(msg, 'additional_kwargs'):
            feedback = msg.additional_kwargs.get("user_feedback", "")
            if feedback:
                eval_context = f"ì´ì „ ì‚¬ìš©ì í”¼ë“œë°±: {feedback}"
                break
    
    all_steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(coaching_steps)])
    
    try:
        baby_context = get_baby_context_string(baby_info)
        
        system_prompt = COACH_AGENT_PROMPT_TEMPLATE.format(
            baby_context=baby_context,
            goal=goal,
            all_steps=all_steps,
            current_step=current_step,
            step_number=current_step_idx + 1,
            total_steps=len(coaching_steps),
            docs_context=docs_context,
            eval_context=eval_context
        )
        
        clean_messages = get_clean_messages_for_generation(messages)
        recent_history = clean_messages[-5:] if len(clean_messages) > 5 else clean_messages
        recent_history = sanitize_messages_for_llm(recent_history)
        
        response = await llm.ainvoke(
            [SystemMessage(content=system_prompt)] + recent_history,
            config={"tags": ["stream_response"]}
        )
        
        state["response"] = response.content.strip()
        state["messages"] = [response]
        
        logger.info(f"âœ… Coach Agent ê°€ì´ë“œ ìƒì„± ì™„ë£Œ (ë‹¨ê³„ {current_step_idx + 1}/{len(coaching_steps)})")
        
    except Exception as e:
        logger.error(f"ì½”ì¹˜ ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        state["response"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ê°€ì´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        state["messages"] = [AIMessage(content=state["response"])]
    
    return state


@track_node_execution_time("coaching_evaluator")
async def coaching_evaluator_node(state: AgentState) -> AgentState:
    """
    Evaluator ë…¸ë“œ (ì½”ì¹­ ì—ì´ì „íŠ¸)
    ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ê²½ë¡œë¥¼ ê²°ì •.
    - success: step_idx + 1 (ë§ˆì§€ë§‰ì´ë©´ completed)
    - retry: Coach Agentë¡œ ë³µê·€ (ë‹¤ë¥¸ ë°©ë²• ì œì•ˆ)
    - stop: paused â†’ Closing
    - chitchat: Coach Agentë¡œ ë³µê·€ (ì§ˆë¬¸ ë‹µë³€ í›„ ì½”ì¹­ ìœ ë„)
    """
    logger.info("===== ğŸ“Š Coaching Evaluator ë…¸ë“œ ì‹¤í–‰ =====")
    
    goal = state.get("goal", "")
    coaching_steps = state.get("coaching_steps", [])
    current_step_idx = state.get("current_step_idx", 0)
    messages = state.get("messages", [])
    
    current_step = coaching_steps[current_step_idx] if coaching_steps and current_step_idx < len(coaching_steps) else ""
    
    # ì‚¬ìš©ìì˜ ìµœì‹  ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_message = msg.content
            break
    
    if not user_message:
        logger.warning("âš ï¸ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return state
    
    llm = get_evaluator_llm()
    if not llm:
        logger.warning("âš ï¸ í‰ê°€ ëª¨ë¸ì´ ì—†ì–´ ê¸°ë³¸ê°’(retry)ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        return state
    
    try:
        eval_prompt = EVALUATOR_PROMPT_TEMPLATE.format(
            goal=goal,
            current_step=current_step,
            step_number=current_step_idx + 1,
            total_steps=len(coaching_steps),
            user_message=user_message
        )
        
        eval_messages = [
            SystemMessage(content=COACHING_EVALUATOR_SYSTEM_PROMPT),
            HumanMessage(content=eval_prompt)
        ]
        
        response = await llm.ainvoke(eval_messages)
        response_text = response.content.strip()
        
        result = parse_json_from_response(response_text)
        
        next_action = result.get("next_action", "retry")
        reason = result.get("reason", "")
        user_feedback = result.get("user_feedback", "")
        
        logger.info(f"âœ… Evaluator íŒë‹¨: {next_action} (ì´ìœ : {reason})")
        
        if next_action == "success":
            new_idx = current_step_idx + 1
            if new_idx >= len(coaching_steps):
                # ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ
                state["current_step_idx"] = new_idx
                state["goal_status"] = "completed"
                logger.info("ğŸ‰ ëª¨ë“  ì½”ì¹­ ë‹¨ê³„ ì™„ë£Œ!")
            else:
                # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
                state["current_step_idx"] = new_idx
                logger.info(f"â¡ï¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™: {new_idx + 1}/{len(coaching_steps)}")
                
        elif next_action == "stop":
            state["goal_status"] = "paused"
            logger.info("â¸ï¸ ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì½”ì¹­ ì¤‘ë‹¨")
            
        elif next_action == "retry":
            # current_step_idxëŠ” ìœ ì§€, Coach Agentì—ì„œ ë‹¤ë¥¸ ë°©ë²• ì œì•ˆ
            logger.info("ğŸ”„ ì¬ì‹œë„: Coach Agentì—ì„œ ë‹¤ë¥¸ ë°©ë²• ì œì•ˆ ì˜ˆì •")
            
        elif next_action == "chitchat":
            # current_step_idxëŠ” ìœ ì§€, Coach Agentì—ì„œ ì§ˆë¬¸ ë‹µë³€ í›„ ì½”ì¹­ ìœ ë„
            logger.info("ğŸ’¬ ì¡ë‹´ ê°ì§€: Coach Agentì—ì„œ ë‹µë³€ í›„ ì½”ì¹­ìœ¼ë¡œ ë³µê·€ ì˜ˆì •")
        
        # í”¼ë“œë°±ì„ ìƒíƒœì— ì €ì¥ (Coach Agentì—ì„œ ì°¸ì¡°ìš©)
        if user_feedback:
            # ìµœì‹  AI ë©”ì‹œì§€ì— í”¼ë“œë°± ì¶”ê°€
            state["messages"] = [AIMessage(
                content="", 
                additional_kwargs={"user_feedback": user_feedback, "eval_action": next_action}
            )]
            
    except Exception as e:
        logger.error(f"Evaluator ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ retry (Coach Agentë¡œ ë³µê·€)
        logger.info("âš ï¸ í‰ê°€ ì‹¤íŒ¨, ê¸°ë³¸ê°’(retry)ìœ¼ë¡œ Coach Agent ë³µê·€")
    
    return state


@track_node_execution_time("closing")
async def closing_node(state: AgentState) -> AgentState:
    """
    Closing ë…¸ë“œ (ì½”ì¹­ ì—ì´ì „íŠ¸)
    ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê³  ê²°ê³¼ë¥¼ ì •ë¦¬.
    - completed: ì¶•í•˜ ë©”ì‹œì§€
    - paused: ìœ„ë¡œ/íœ´ì‹ ê¶Œìœ  ë©”ì‹œì§€
    """
    logger.info("===== ğŸ Closing ë…¸ë“œ ì‹¤í–‰ =====")
    
    goal = state.get("goal", "")
    coaching_steps = state.get("coaching_steps", [])
    current_step_idx = state.get("current_step_idx", 0)
    goal_status = state.get("goal_status", "completed")
    baby_info = state.get("baby_info", {})
    messages = state.get("messages", [])
    
    llm = get_generator_llm()
    if not llm:
        if goal_status == "completed":
            state["response"] = "ğŸ‰ ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆë‹¤! ì •ë§ ëŒ€ë‹¨í•´ìš”! ì•ìœ¼ë¡œë„ ì•„ê¸°ì™€ í•¨ê»˜ í–‰ë³µí•œ ì‹œê°„ ë³´ë‚´ì„¸ìš”."
        else:
            state["response"] = "ì˜¤ëŠ˜ì€ ì—¬ê¸°ê¹Œì§€ í• ê²Œìš”. ì¶©ë¶„íˆ ì˜í•˜ê³  ê³„ì„¸ìš”! ì–¸ì œë“  ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆì–´ìš” ğŸ’ª"
        state["messages"] = [AIMessage(content=state["response"])]
        return state
    
    try:
        baby_context = get_baby_context_string(baby_info)
        all_steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(coaching_steps)])
        
        # ì™„ë£Œí•œ ë‹¨ê³„ ìˆ˜ ê³„ì‚°
        completed_count = min(current_step_idx, len(coaching_steps))
        
        system_prompt = CLOSING_PROMPT_TEMPLATE.format(
            baby_context=baby_context,
            goal=goal,
            all_steps=all_steps,
            completed_steps=completed_count,
            total_steps=len(coaching_steps),
            status=goal_status
        )
        
        clean_messages = get_clean_messages_for_generation(messages)
        recent_history = clean_messages[-10:] if len(clean_messages) > 10 else clean_messages
        
        response = await llm.ainvoke(
            [SystemMessage(content=system_prompt)] + recent_history,
            config={"tags": ["stream_response"]}
        )
        
        state["response"] = response.content.strip()
        state["messages"] = [response]
        
        logger.info(f"âœ… Closing ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ (ìƒíƒœ: {goal_status}, ì™„ë£Œ: {completed_count}/{len(coaching_steps)})")
        
    except Exception as e:
        logger.error(f"Closing ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        state["response"] = "ì½”ì¹­ì„ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ë„ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ’•"
        state["messages"] = [AIMessage(content=state["response"])]
    
    return state

def get_clean_messages_for_generation(messages):
    """
    ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì—ì„œ ìµœê·¼ HumanMessageê¹Œì§€ë§Œ ë‚¨ê¸°ê³  ê·¸ ì´í›„ì˜ Agent í™œë™ ë¡œê·¸ëŠ” ì œê±°
    
    Args:
        messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ì •ë¦¬ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    if not messages:
        return []
    
    # 1. ë’¤ì—ì„œë¶€í„° íƒìƒ‰í•˜ì—¬ 'ê°€ì¥ ìµœê·¼ì˜ HumanMessage' ì¸ë±ìŠ¤ ì°¾ê¸°
    last_human_index = -1
    for i, msg in enumerate(reversed(messages)):
        if isinstance(msg, HumanMessage):
            # reversed ìƒíƒœì´ë¯€ë¡œ ì›ë˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            last_human_index = len(messages) - 1 - i
            break
            
    # 2. HumanMessageê°€ ì—†ë‹¤ë©´? (ì˜ˆì™¸ì²˜ë¦¬)
    if last_human_index == -1:
        return messages[-10:]  # ê·¸ëƒ¥ ìµœê·¼êº¼ ë°˜í™˜
        
    # 3. [í•µì‹¬] ë§ˆì§€ë§‰ ì§ˆë¬¸ê¹Œì§€ë§Œ ë‚¨ê¸°ê³ , ê·¸ ë’¤ì˜ Agent í™œë™ ë¡œê·¸ëŠ” ì „ë¶€ ì‚­ì œ
    clean_history = messages[:last_human_index + 1]
    
    return clean_history


def sanitize_messages_for_llm(messages):
    """
    LLMì— ì „ì†¡í•˜ê¸° ì „ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ì—¬ OpenAI API ê·œì¹™ì„ ì¤€ìˆ˜í•˜ë„ë¡ ë³´ì¥.
    
    ê·œì¹™:
    - ToolMessageëŠ” ë°˜ë“œì‹œ ì§ì „ì— tool_callsê°€ í¬í•¨ëœ AIMessageê°€ ìˆì–´ì•¼ í•¨
    - tool_callsë§Œ ìˆê³  contentê°€ ì—†ëŠ” AIMessageëŠ” ëŒ€ì‘í•˜ëŠ” ToolMessage ì—†ì´ëŠ” ë¬´ì˜ë¯¸
    - ê³ ì•„(orphaned) ToolMessageì™€ tool_calls AIMessageë¥¼ ì œê±°
    
    Args:
        messages: ìŠ¬ë¼ì´ì‹±ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        OpenAI APIì— ì•ˆì „í•˜ê²Œ ì „ì†¡í•  ìˆ˜ ìˆëŠ” ì •ì œëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    if not messages:
        return []
    
    result = []
    i = 0
    
    while i < len(messages):
        msg = messages[i]
        
        if isinstance(msg, ToolMessage):
            # ToolMessage: ì§ì „ ë©”ì‹œì§€ê°€ tool_callsë¥¼ ê°€ì§„ AIMessageì´ê±°ë‚˜ ë‹¤ë¥¸ ToolMessageì¸ì§€ í™•ì¸
            if result and (
                (isinstance(result[-1], AIMessage) and getattr(result[-1], "tool_calls", None))
                or isinstance(result[-1], ToolMessage)
            ):
                result.append(msg)
            else:
                # ê³ ì•„ ToolMessage â†’ ìŠ¤í‚µ
                logger.debug(f"ğŸ§¹ ê³ ì•„ ToolMessage ì œê±°: {getattr(msg, 'name', 'unknown')}")
            i += 1
            continue
        
        if isinstance(msg, AIMessage) and getattr(msg, "tool_calls", None):
            # AIMessage with tool_calls: ë‹¤ìŒì— ëŒ€ì‘í•˜ëŠ” ToolMessageê°€ ìˆëŠ”ì§€ í™•ì¸
            has_tool_response = (i + 1 < len(messages) and isinstance(messages[i + 1], ToolMessage))
            if has_tool_response:
                result.append(msg)
            else:
                # ëŒ€ì‘í•˜ëŠ” ToolMessage ì—†ìŒ â†’ ìŠ¤í‚µ
                logger.debug("ğŸ§¹ ëŒ€ì‘ ToolMessage ì—†ëŠ” tool_calls AIMessage ì œê±°")
            i += 1
            continue
        
        # HumanMessage, SystemMessage, ì¼ë°˜ AIMessage â†’ ê·¸ëŒ€ë¡œ ìœ ì§€
        result.append(msg)
        i += 1
    
    return result
